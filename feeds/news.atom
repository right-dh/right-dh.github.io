<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="/feeds/news.atom" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2022-03-16T09:52:35+00:00</updated><id>/feeds/news.atom</id><title type="html">RGCL’s blog | News</title><subtitle>Blog of the Research Group in Computational Linguistics &lt;br /&gt;at the University of Wolverhampton</subtitle><author><name>RGCL</name></author><entry><title type="html">Search Solutions Tutorial on Natural Language Processing</title><link href="/news/2021-12-1-search-solution-tutorial-nlp/" rel="alternate" type="text/html" title="Search Solutions Tutorial on Natural Language Processing" /><published>2021-12-01T00:00:00+00:00</published><updated>2021-12-01T00:00:00+00:00</updated><id>/news/</id><content type="html" xml:base="/news/2021-12-1-search-solution-tutorial-nlp/"><![CDATA[<p><em>Search Solutions</em> is an annual event run by the Information Retrieval Specialist Group, the section of the British Computer Society which has a special interest in search engines. This year it took place on Wednesday 24th November, and was held online for invited speakers from industry to talk about their work in information retrieval. The British Computer Society has new offices at 25 Copthall Avenue in London, near the Bank of England. On the day before, a series of tuorials designed to introduce people to related topics were held, such as one given by Ingo Frommholz from our own computing department on search engine evaluation.</p>

<p>The tutorial on Natural Language Processing was given by myself. Unlike the others, it was an all-day event, and held face-to-face. After having had experience of online teaching during the pandemic, I know that I prefer the closer interaction with the students which comes with face-to-face teaching.</p>

<p>The contents of the tutorial were almost the same as the first three weeks of lectures that I give on the MA Computational Linguistics module in RIILP. I used the structure of the textbook by Jurafsky and Martin as a skeleton, but brought in other things such as the practical exercises  from the Edinburgh Textbooks in Empirical Linguistics on stemming and automatic part of speech tagging. Stemming covers techniques for regarding different grammatical forms of a word as being related to each other, and part-of-speech tagging is assigning a part-of-speech category (such as noun or verb) to each word in the input sentence. I used the first edition of Jurafsky and Martin to open the discussion with a short dialogue between Dave the astronaut and HAL the computer from the film “2001 – A Space Odyssey”. What natural language techniques would HAL need to know to carry out this conversation?</p>

<p>At the event, I was pleased to see some old friends in the audience, including Ingo in the morning, before his own workshop began.</p>

<p>More details are available at: <a href="https://www.bcs.org/membership-and-registrations/member-communities/information-retrieval-specialist-group/conferences-and-events/search-solutions/search-solutions-2021/">https://www.bcs.org/membership/member-communities/information-retrieval-specialist-group/conferences-and-events/search-solutions/search-solutions-2021/</a></p>

<p><em>Michael Oakes</em></p>]]></content><author><name>Michael Oakes</name></author><summary type="html"><![CDATA[Search Solutions is an annual event run by the Information Retrieval Specialist Group, the section of the British Computer Society which has a special interest in search engines. This year it took place on Wednesday 24th November, and was held online for invited speakers from industry to talk about their work in information retrieval. The British Computer Society has new offices at 25 Copthall Avenue in London, near the Bank of England. On the day before, a series of tuorials designed to introduce people to related topics were held, such as one given by Ingo Frommholz from our own computing department on search engine evaluation.]]></summary></entry><entry><title type="html">Winners of the Vice-Chancellor’s Awards for Staff Excellence</title><link href="/news/2021-11-19-vice-chancellor-award-staff-excellence/" rel="alternate" type="text/html" title="Winners of the Vice-Chancellor’s Awards for Staff Excellence" /><published>2021-11-19T00:00:00+00:00</published><updated>2021-11-19T00:00:00+00:00</updated><id>/news/</id><content type="html" xml:base="/news/2021-11-19-vice-chancellor-award-staff-excellence/"><![CDATA[<p>Earlier this week the Vice-Chancellor’s Awards for Staff Excellence took place. Our Admin Team – April, Suman, Kate, Amanda and Emma – were nominated and won their category of ‘<em>Excellence in partnerships</em>’. If you were unable to join the event, you can watch it back on <a href="https://youtu.be/_pqhvrpmC-c">YouTube</a>. The <a href="https://www.wlv.ac.uk/staff/vice-chancellors-awards-for-staff-excellence/staff-awards-2021/">staff awards brochure</a> can now also be viewed online, which includes an overview of all the shortlisted nominees.</p>

<h3 id="excellence-in-partnerships">Excellence in partnerships</h3>

<p>“<em>An individual or a team that has demonstrated outstanding commitment and professionalism through partnership working, to a high-quality service to our students, staff or stakeholders</em>”.</p>

<p><strong>Winners:</strong> RIILP Administrative Team: April Harper, Amanda Bloore, Suman Hira, Kate Wilson, Emma Franklin for supporting the institutional research trajectory by providing infrastructure, systems and processes as well as a positive attitude.</p>

<p>Congratulations Ladies!</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Earlier this week the Vice-Chancellor’s Awards for Staff Excellence took place. Our Admin Team – April, Suman, Kate, Amanda and Emma – were nominated and won their category of ‘Excellence in partnerships’. If you were unable to join the event, you can watch it back on YouTube. The staff awards brochure can now also be viewed online, which includes an overview of all the shortlisted nominees.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/2021-11-19-vice-chancellor-award-staff-excellence.jpg" /><media:content medium="image" url="/2021-11-19-vice-chancellor-award-staff-excellence.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">EM TTI Application Portal now open!</title><link href="/news/2021-10-6-emtti-application-portal-open/" rel="alternate" type="text/html" title="EM TTI Application Portal now open!" /><published>2021-10-06T00:00:00+00:00</published><updated>2021-10-06T00:00:00+00:00</updated><id>/news/</id><content type="html" xml:base="/news/2021-10-6-emtti-application-portal-open/"><![CDATA[<h2 id="erasmus-mundus-european-masters-in-technology-for-translation-and-interpreting-em-tti">Erasmus Mundus European Master’s in Technology for Translation and Interpreting (EM TTI)</h2>

<h3 id="call-for-applications-for-start-date-september-2022">Call for applications for start date September 2022</h3>

<p>Scholarship application deadline: 15th January 2022</p>

<p>Self-funded application deadline: 1st July 2022</p>

<p>We invite applications for the new Erasmus Mundus European Master’s programme in Technology for Translation and Interpreting (EM TTI) with a start date of September 2022. The programme, run by University of Wolverhampton, University of Malaga, New Bulgarian University and Ghent University, offers students the opportunity to study at two international institutions and to undertake work placements with industry leaders around the world. A competitive Erasmus Mundus scholarship is offered to the highest-ranking applicants. Both European and non-European students can apply.</p>

<p>How to apply: <a href="https://em-tti.eu/how-to-apply">https://em-tti.eu/how-to-apply</a></p>

<p>Course Fees: <a href="https://em-tti.eu/about-masters/course-fees/">https://em-tti.eu/about-masters/course-fees/</a></p>

<p>Should you have any questions, please do not hesitate to contact the EM TTI team at <a href="mailto:enquiries@em-tti.eu">enquiries@em-tti.eu</a>.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Erasmus Mundus European Master’s in Technology for Translation and Interpreting (EM TTI)]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/2021-10-6-emtti-application-portal-open.jpg" /><media:content medium="image" url="/2021-10-6-emtti-application-portal-open.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">3 PhD studentships on NLP and DL approaches in Digital Humanities</title><link href="/news/2021-7-6-three-studentships-nlp-dl-dh/" rel="alternate" type="text/html" title="3 PhD studentships on NLP and DL approaches in Digital Humanities" /><published>2021-07-06T00:00:00+00:00</published><updated>2021-07-06T00:00:00+00:00</updated><id>/news/</id><content type="html" xml:base="/news/2021-7-6-three-studentships-nlp-dl-dh/"><![CDATA[<h3 id="research-group-in-computational-linguistics">Research Group in Computational Linguistics,</h3>
<h3 id="research-institute-of-information-and-language-processing">Research Institute of Information and Language Processing,</h3>
<h3 id="university-of-wolverhampton">University of Wolverhampton</h3>

<p><strong>** Closing date 19 July 2021 **</strong></p>

<p>The Research Group in Computational Linguistics (<a href="http://rgcl.wlv.ac.uk">http://rgcl.wlv.ac.uk</a>) at the Research Institute of Information and Language Processing of the University of Wolverhampton invites applications</p>

<p>for three PhD studentships with the prospective PhD students working on the following topics: (i) Natural Language Processing (NLP) and Deep Learning (DL) in Computational History studies, (ii) NLP and DL in Computational Literature studies and (iii) NLP and DL in Computational Film Studies.</p>

<p>These are 3-year funded bursaries which will include a stipend towards living expenses (£15,609 per year) with the tuition fees and the research fees included.</p>

<p>Applicants will submit PhD research proposals not exceeding 2,000 words. The applicants are invited to propose an original computational history study, computational literature study or computational film study where NLP and DL techniques are employed.</p>

<p><em>Prerequisites</em></p>

<p>A successful applicant must have a good honours degree or equivalent in Computer Science, Computational Linguistics, Digital Humanities or Linguistics, with good programming skills, and knowledge of Deep Learning and Natural Language Processing.</p>

<p><em>Application procedure</em></p>

<p>Applications must include:</p>

<ul>
  <li>Research proposal not exceeding 2,000 words (see above)</li>
  <li>A curriculum vitae listing degrees awarded, courses covered and marks obtained, publications, relevant experience and names of two referees who could be contacted for a reference</li>
  <li>Cover letter with statement of research interests, outlining why you are interested in this PhD position/topic, how you plan to approach the research task and why you consider your experience is relevant.</li>
</ul>

<p>Schedule</p>

<p>The application deadline is 19 July 2021. The short-listed candidates will be notified by email by 20 July 2021 and interviewed via Zoom on 21 or 22 July 2021. The starting date of the PhD position is 1 September 2021 or any time as soon as possible after that.</p>

<p>Established by Prof Mitkov in 1998, the research group in Computational Linguistics delivers cutting-edge research in a number of NLP areas. The results from the UK research assessment exercises confirm the research group in Computational Linguistics as one of the top performers in UK and international research with its research assessed as ‘internationally leading, internationally excellent and internationally recognised’.</p>

<p>The PhD students will be members of the newly established Responsible Digital Humanities Research Lab which is part of the Research Group of Computational Linguistics.</p>

<p>Applications should be sent by email to Prof Dr Ruslan Mitkov, 
Director of Research Institute of Information and Language Processing,
University of Wolverhampton</p>

<p>Email: <a href="mailto:R.Mitkov@wlv.ac.uk">R.Mitkov@wlv.ac.uk</a></p>

<p>and copied to Prof Mitkov’s PAs Miss Suman Hira (<a href="mailto:suman.hira@wlv.ac.uk">suman.hira@wlv.ac.uk</a>) and Mrs April Harper (<a href="mailto:a.harper2@wlv.ac.uk">a.harper2@wlv.ac.uk</a>).</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Research Group in Computational Linguistics, Research Institute of Information and Language Processing, University of Wolverhampton]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/2021-7-6-three-studentships-nlp-dl-dh.png" /><media:content medium="image" url="/2021-7-6-three-studentships-nlp-dl-dh.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Papers accepted at ACL-IJCNLP 2021 and NAACL-HWT 2021</title><link href="/news/2021-5-18-fred-blain-accepted-qe-papers/" rel="alternate" type="text/html" title="Papers accepted at ACL-IJCNLP 2021 and NAACL-HWT 2021" /><published>2021-05-18T00:00:00+00:00</published><updated>2021-05-18T00:00:00+00:00</updated><id>/news/Congratulations%20to%20Dr%20Fr%C3%A9d%C3%A9ric%20Blain%20who%20has%20had%20the%20following%20papers%20accepted%20at%20upcoming%20conferences.</id><content type="html" xml:base="/news/2021-5-18-fred-blain-accepted-qe-papers/"><![CDATA[<p><strong>Title</strong>: <em>Knowledge Distillation for Quality Estimation</em></p>

<p><strong>Authors</strong>: <em>Amit Gajbhiye, Marina Fomicheva, Fernando Alva-Manchego, Frédéric Blain, Abiola Obamuyide, Nikolaos Aletras and Lucia Specia</em></p>

<p><strong>Abstract</strong>: Quality Estimation (QE) is the task of automatically predicting Machine Translation quality in the absence of reference translations, making it applicable in real-time settings, such as translating online social media conversations. Recent success in QE stems from the use of multilingual pre-trained representations,where very large models lead to impressive results. However, the inference time, disk and memory requirements of such models do not allow for wide usage in the real world.</p>

<p>Attempts have been made at making pre-trained representations less resource-hungry by using knowledge distillation, but the resulting models remain prohibitively large for many usage scenarios.Instead of building upon distilled pre-trained representations, we propose to transfer knowledge from a strong QE teacher model to a much smaller model with a different, shallower architecture. In combination with a confidence-based data augmentation approach, we show that it is possible to create light-weight QE models that achieve comparable results to distilled pre-trained representations with 8x fewer parameters.</p>

<p>This paper should appear in the Findings of ACL-IJCNLP 2021 (see <a href="https://2021.aclweb.org/">https://2021.aclweb.org/</a>).</p>

<hr />

<p><strong>Title</strong>: <em>Backtranslation Feedback Improves User Confidence in MT, Not Quality</em></p>

<p><strong>Authors</strong>: <em>Vilém Zouhar, Michal Novák, Matúš Žilinec, Ondřej Bojar, Mateo Obregón, Robin L. Hill, Frédéric Blain, Marina Fomicheva, Lucia Specia, Lisa Yankovskaya</em></p>

<p><strong>Abstract</strong>: Translating text into a language unknown to the text’s author, dubbed outbound translation, is a modern need for which the user experience has significant room for improvement, beyond the basic machine translation facility. We demonstrate this by showing three ways in which user confidence in the outbound translation, as well as its overall final quality, can be affected: backward translation, quality estimation (with alignment) and source paraphrasing. In this paper, we describe an experiment on outbound translation from English to Czech and Estonian. We examine the effects of each proposed feedback module and further focus on how the quality of machine translation systems influence these findings and the user perception of success. We show that backward translation feedback has a mixed effect on the whole process: it increases user confidence in the produced translation, but not the objective quality.</p>

<p>This paper will appear at NAACL-HWT 2021 (<a href="https://2021.naacl.org/">https://2021.naacl.org/</a>).</p>

<p>The paper can also be found here: <a href="https://arxiv.org/abs/2104.05688">https://arxiv.org/abs/2104.05688</a>.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Title: Knowledge Distillation for Quality Estimation]]></summary></entry><entry><title type="html">Paper accepted at ACL-IJCNLP 2021</title><link href="/news/2021-5-11-tharindu-ranasinghe-accepted-qe-paper/" rel="alternate" type="text/html" title="Paper accepted at ACL-IJCNLP 2021" /><published>2021-05-11T00:00:00+00:00</published><updated>2021-05-11T00:00:00+00:00</updated><id>/news/Congratulations%20to%20one%20of%20our%20PhD%20students%20Tharindu%20Ranasinghe%20%E2%80%93%20who%20has%20had%20a%20paper%20accepted%20at%20ACL-IJCNLP%202021.</id><content type="html" xml:base="/news/2021-5-11-tharindu-ranasinghe-accepted-qe-paper/"><![CDATA[<p><strong>Title</strong>: <em>An Exploratory Analysis of Multilingual Word Level Quality Estimation with Cross-Lingual Transformers.</em></p>

<p><strong>Authors</strong>: <em>Tharindu Ranasinghe, <a href="https://dinel.org.uk/">Constantin Orasan</a>, <a href="http://www.wlv.ac.uk/ruslanmitkov">Ruslan Mitkov</a>.</em></p>

<p><strong>Abstract</strong>: Most studies on word level Quality Estimation (QE) of machine translation focus on language-specific models. The obvious disadvantages of these approaches are the need for labelled data for each language pair and the high cost required to maintain several language-specific models. To overcome these problems, we explore different approaches to multilingual word level QE. We show that these QE models perform on-par with the current language-specific models. In the case of zero-shot QE, we show that it is possible to accurately predict word level quality for any given new language pair from models trained on other language pairs. Our findings indicate that the word level QE models based on powerful pre-trained transformers we propose on this paper generalise well across languages, making them more useful in real-world scenarios.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Title: An Exploratory Analysis of Multilingual Word Level Quality Estimation with Cross-Lingual Transformers.]]></summary></entry><entry><title type="html">Teaching and Learning in a Pandemic</title><link href="/news/2020-11-12-teaching-learning-pandemic/" rel="alternate" type="text/html" title="Teaching and Learning in a Pandemic" /><published>2020-11-12T00:00:00+00:00</published><updated>2020-11-12T00:00:00+00:00</updated><id>/news/It%20is%20good%20to%20be%20back%20on%20site%20!%20After%20a%20year%20of%20online%20teaching,%20we%20are%20finally%20back%20on%20campus%20to%20meet%20our%20students%20and%20resume%20teaching%20in%20person.%20In%20this%20blog%20post,%20both%20teaching%20staff%20and%20students%20confide%20about%20the%20situation%20being%20(almost)%20back%20to%20normal.</id><content type="html" xml:base="/news/2020-11-12-teaching-learning-pandemic/"><![CDATA[<h3 id="first-face-to-face-interaction-for-a-very-long-time"><strong>First face to face interaction for a very long time.</strong></h3>

<p>Dr Le An Ha, Lecturer:</p>

<blockquote>
  <p>Last Thursday, as the country went into the second lockdown, we conducted our first face to face practical session. It was very emotional (at least for me). I could not only feel, but also see the massive amount of efforts that has been spent, so that such a simple thing can happen. Students had to travel from their home countries, facing risks and quarantines. Facilities have to make the classroom Covid secured, with individual tables rightly spaced. The university is doing their best to keep itself open. All that efforts, so that us (lecturers and students) can have those two hours of valuable face to face teaching and learning. The session was very productive. We will do it again this week, but will improve it further by inviting students who cannot present physically to join in virtually. Let see how it goes. I bet that there will be problems, but none would prove too big to overcome.</p>
</blockquote>

<hr />

<p>Nikola Spasovski, Student:</p>

<blockquote>
  <p>When the lockdown was announced, many of us thought that face to face teaching will be postponed for some additional time. Luckily, the UoW is doing their best, following a lot of covid protocols, to keep the facilities a safe place and last Thursday we had our first practical session on campus. The session was very productive, we went through the material we studied in class but also learnt some (very handy) bonus lines of codes! Also, it was nice to meet in person everyone who made it to the UK.</p>
</blockquote>

<hr />

<p>Katerina Poltorak, Student:</p>
<blockquote>
  <p>It was a lovely practical session! I was happy to meet Dr. Ha and the fellow students. During the class Dr. Ha shared his experience in programming and was trying to get us think a programming language. I appreciate the effort of the EMTTI Team and the University of Wolverhampton to provide this opportunity of offline classes for us given the current state of affairs! Many thanks.”</p>
</blockquote>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[First face to face interaction for a very long time.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/2020-11-12-teaching-learning-pandemic.jpg" /><media:content medium="image" url="/2020-11-12-teaching-learning-pandemic.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">PhD Research Diaries: Dr. Maria Kunilovskaya</title><link href="/news/2020-11-3-research-diaries-maria-kunilovskaya/" rel="alternate" type="text/html" title="PhD Research Diaries: Dr. Maria Kunilovskaya" /><published>2020-11-03T00:00:00+00:00</published><updated>2020-11-03T00:00:00+00:00</updated><id>/news/Welcome%20to%20the%20first%20blog%20of%20our%20new%20series%20of%20PhD%20Research%20Diaries%20%E2%80%93%20as%20we%20all%20work%20at%20home%20during%20the%20pandemic,%20the%20opportunity%20for%20that%20informal%20research%20chat%20has%20diminished,%20if%20not%20disappeared.%20Although%20perhaps%20a%20poor%20substitute,%20let%20us%20start%20the%20research%20chat%20with%20a%20post%20from%20one%20of%20our%20full%20time%20PhD%20students:%20Dr.%20Maria%20Kunilovskaya.</id><content type="html" xml:base="/news/2020-11-3-research-diaries-maria-kunilovskaya/"><![CDATA[<p>I am engaged in a time- and effort-consuming, but insightful and potentially useful <strong>experiment in human translation quality annotation</strong>.</p>

<p>(It is a pity I cannot discuss it over lunch! No technical progress in Zoom, MS teams or Skype will be able to compensate for the opportunity to ruminate the research ideas over lunch and for the motivations of the office life. Let’s see whether blogging can be helpful.)</p>

<p>One of the problems I faced in my attempts to build a quality estimation system for human translation is the lack of a reliable and available gold standard.</p>

<p>Which quality labels are most useful in a machine learning setting? But more importantly how do you get them?</p>

<h3 id="1-previous-attempts">1. Previous attempts</h3>

<p>I started my experiments with implementing two of the possible solutions:</p>

<p><strong>1.1 ‘Good’ vs. ‘Bad’.</strong> I used graded exam translations produced by professional translation programmes in several universities as well as data from a number of translation contests to build a quality annotated dataset, which featured <strong>binary labels</strong> (‘good’ vs. ‘bad’). We assumed that a binary classification into sharply opposed classes can be an easy task for a reasonably sophisticated learning setup. The improved dataset counted more than 400 texts of about 400 words each. Our best results on the proven translationese features reached accuracy of 67% (with the chance level as 55%). See details in Kunilovskaya, M., &amp; Lapshinova-Koltunski, E. (2019). Translationese Features as Indicators of Quality in English-Russian Human Translation. In Proceedings of the 2nd Workshop on Human-Informed Translation and Interpreting Technology (HiT-IT 2019) (pp. 47–56).</p>

<p>I also tried other approaches to text representation, ranging from tf-idf scaled character trigrams (and other bag-of-word representations) to get the accuracy of good-bad classification of 68% and bilingual vectors learnt on lemmatised corpora + Siamese architecture of bidirectional LSTM to feed the averaged vectors for the source and target texts. The latter experiment yielded the accuracy of 64%</p>

<p>Those efforts indicated that translation quality is either extremely difficult to learn or that I might have a problem with the labels in the dataset or the binary setup in general. The latter option sprang to mind after I verified the labels by re-annotating 20% of the data and removing a few texts that caused disagreements.</p>

<p><strong>1.2 Professional vs Student.</strong> Another way to approach the lack of reliable labels is to utilise the natural classes of texts, which can be assumed to reflect their quality (aka distant supervision). A typical case of such classes is (well-published) <strong>professional and learner</strong> translations. On the same set of morphosyntactic indicators of translationese we got the accuracy of 78% (see details in Kunilovskaya, M., &amp; Lapshinova-Koltunski, E. (2020). Lexicogrammatic Translationese across Two Targets and Competence Levels. Proceedings Of the 12th Conference on Language Resources and Evaluation (LREC 2020), 4102–4112). While this is an impressive achievement, given our trials with good-bad labels, we need to accept that professionalism is an adequate proxy for translation quality and that the student and professional collections do not differ much in terms of register. By assuming that professionalism is quality in this setting we effectively ignore the many factors associated with text production for students and professional (levels of responsibility, time constraints, levels of stress, extralinguistic motivations and situational conventions).</p>

<h3 id="2-towards-a-continuous-sentence-level-quality-score">2. Towards a continuous sentence-level quality score</h3>

<p>The current annotation experiment aims to produce human judgments about translation quality in the Direct Assessment (DA) setting popular today in the field of machine translation (MT). It is going to be compared with the existing score based on error annotation to try and offer a triangulation of the human quality estimates.</p>

<p><strong>(1) Annotator teams.</strong> The experiments involves 12 volunteers who are final year linguistics degree BA students in a Russian university. All participants have Russian L1 and English at B2 level; they are evaluating translations from English into Russian. They are assigned to <strong>two teams</strong>. Each team includes a group of <strong>three translators</strong>, i.e. students who have attended theoretical and practical courses in translation studies and <strong>three linguists</strong>, i.e. students who major in English teaching or contrastive linguistics. This profiles are supposed to give insights into the impact of (almost complete) translation education in the task of evaluating translation quality.</p>

<p><strong>(2) Data.</strong> The student translations come from the error-annotated subset of Russian Learner Translator Corpus (<a href="https://www.rus-ltc.org/search">www.rus-ltc.org</a>) limited to general domain mass-media texts. Error annotation is used to produce a quality score to cross-validate the annotations in the current experiment. Getting the quality score from error annotations is again a matter of subjectively assigned weights, unfortunately. We decided to go with the following procedure: we calculate a translation’s negative score for language and content errors assigning the following weights to the attributes: ‘minor’: 10, ‘major’: 20, ‘critical’: 30, ‘kudo’: -10. To get the quality score for a text we subtract this score from a 100. To get one quality score for a target text we average the two scores for fluency and accuracy based on the number and weights for language and content errors.</p>

<p>For annotation we offer texts that come from the extreme good-bad categories to provide sharp contrasts and clear quality distinctions in the data.</p>

<p><strong>(3) Results of the calibration session.</strong> The experiments started in early October with a series of enlightening calibration sessions. Inspired by the reasoning in Graham et al (2013, 2017) and Deams et al (2013), where they suggest that fluency should be judged independently of adequacy/accuracy, we arranged for the annotators to evaluate translations in two conditions: as a text in the target language, independent of its source (fluency aspect of translation quality) and in the bilingual setting where the annotators are asked to compare the source segment and the target segment.</p>

<p>However, the results of the calibration session indicated that the participants struggle with separating the two aspects. In particular, even in the second round of annotation following an extended session analysing the oddities in the scores assigned in the first round, the inter-rater agreement was very low and the average annotated scores were miles away from the ones calculated from errors, annotated by a translation examiner in the same text. The discrepancies were particularly noticeable in the accuracy setting.</p>

<p>This made me reconsider the experiment and respect the arguments in Callison-Burch et al. (2007) and Guzmán et al. (2019) who argue for syncretic quality annotation.</p>

<p>The third round of calibration in the setting which does not single out traditional quality aspects (fluency, accuracy) but asks the annotator to indicate whether a Russian segment is an adequate translation of the English segment, given the context, returns reasonable inter-rater agreement and the (expected) better match with the error-based scores, which have the role of gold standard in this annotation experiment.</p>

<p>Interestingly, based on the limited data from the calibration sessions, linguists tent to be more critical in their estimates, there is also less agreement between the raters with no prior translation education. On the other hand, translates tend to agree more and are more forgiving towards the work of their fellows in the profession.</p>

<p><strong>(4) Task.</strong> The experiment is set up on the QuestionPro platform which importantly offers a slider question and unlimited number of surveys and participants for free, which suits our needs. While the annotation takes place on a sentence level, the task page contains a complete text to provide access to cohesion and textuality issues in translations.</p>

<p>After the lessons learnt from several calibration sessions, we issued the first batch of 40 text pairs (922 sentence pairs) for annotation. The task is now formulated as “Read the source text. Use the slider to indicate how much you agree that the text in bold is an adequate translation of the original English sentence, given the context.”</p>

<p>We use a 100-point slider in accordance with the DA method of benchmarking translation quality in MT. It is supposed to alleviate the pressure to choose between 5 or 7 discreet bins in a traditional Likert scale setup. We also repeatedly urged the annotators to pay attention to the textual aspects of quality that can only be noticed in context, but have to be annotated on the sentence level (see Voita et al. 2019).</p>

<p>Naturally, I would be happy to get any feedback or ideas how to adjust the experiment setting to return the most reliable results.</p>

<p>Thanks for listening, anyway :)</p>

<p><em>Maria Kunilovskaya</em></p>]]></content><author><name>Maria Kunilovskaya</name></author><summary type="html"><![CDATA[I am engaged in a time- and effort-consuming, but insightful and potentially useful experiment in human translation quality annotation.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/2020-11-3-research-diaries-maria-kunilovskaya.jpg" /><media:content medium="image" url="/2020-11-3-research-diaries-maria-kunilovskaya.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Wolverhampton researchers collaborate on BBC’s “Novels That Shaped Our World”</title><link href="/news/2019-8-23-bbc-shape-our-world/" rel="alternate" type="text/html" title="Wolverhampton researchers collaborate on BBC’s “Novels That Shaped Our World”" /><published>2019-08-23T00:00:00+00:00</published><updated>2019-08-23T00:00:00+00:00</updated><id>/news/</id><content type="html" xml:base="/news/2019-8-23-bbc-shape-our-world/"><![CDATA[<p>We are working with BBC Arts and Faculty of Arts on a new engagement project to mark the 300th anniversary of the English Language Novel.</p>

<p>The interdisciplinary project unites research by Wolverhampton’s Research Group for Computational Linguistics, including Dr Sara Moze, Richard Evans and Dr Emad Mohamed, and from English and Creative Writing staff, led by Dr Aidan Byrne. The project is seeking support from the Arts and Humanities Research Council.</p>

<p>There is more information on the University website if you would like to find out more about the project: <a href="https://www.wlv.ac.uk/about-us/news-and-events/latest-news/2019/august-2019/wolverhampton-researchers-collaborate-on-bbcs-novels-that-shaped-our-world.php">https://www.wlv.ac.uk/about-us/news-and-events/latest-news/2019/august-2019/wolverhampton-researchers-collaborate-on-bbcs-novels-that-shaped-our-world.php</a>.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[We are working with BBC Arts and Faculty of Arts on a new engagement project to mark the 300th anniversary of the English Language Novel.]]></summary></entry><entry><title type="html">Paper accepted at NAACL 2019</title><link href="/news/2019-2-28-marcos-zampieri-accepted-paper/" rel="alternate" type="text/html" title="Paper accepted at NAACL 2019" /><published>2019-02-28T00:00:00+00:00</published><updated>2019-02-28T00:00:00+00:00</updated><id>/news/Congratulations%20to%20Marcos%20Zampieri,%20whose%20paper%20has%20been%20accepted%20at%20NAACL%202019.</id><content type="html" xml:base="/news/2019-2-28-marcos-zampieri-accepted-paper/"><![CDATA[<p><strong>Title</strong>: <em>Predicting the Type and Target of Offensive Posts in Social Media</em></p>

<p><strong>Authors</strong>: <em>Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra and Ritesh Kumar</em></p>

<p><strong>Abstract</strong>: As offensive content has become pervasive in social media, there has been much research in identifying potentially offensive messages. However, previous work on this topic did not consider the problem as a whole, but rather focused on detecting very specific types of offensive content, e.g., hate speech, cyberbulling, or cyber-aggression. In contrast, here we target several different kinds of offensive content. In particular, we model the task hierarchically, identifying the type and the target of offensive messages in social media. For this purpose, we complied the Offensive Language Identification Dataset (OLID), a new dataset with tweets annotated for offensive content using a fine-grained three-layer annotation scheme, which we make publicly available. We discuss the main similarities and differences between OLID and pre-existing datasets for hate speech identification, aggression detection, and similar tasks. We further experiment with and we compare the performance of different machine learning models on OLID.</p>

<p>You may access the NAACL paper here: <a href="https://arxiv.org/abs/1902.09666">https://arxiv.org/abs/1902.09666</a>.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Title: Predicting the Type and Target of Offensive Posts in Social Media]]></summary></entry></feed>