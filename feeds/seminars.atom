<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="/feeds/seminars.atom" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2022-03-16T09:52:35+00:00</updated><id>/feeds/seminars.atom</id><title type="html">RGCL’s blog | Seminars</title><subtitle>Blog of the Research Group in Computational Linguistics &lt;br /&gt;at the University of Wolverhampton</subtitle><author><name>RGCL</name></author><entry><title type="html">Multimodal analysis using TV data: new tools for the study of language and gesture</title><link href="/seminars/2022-03-09-daniel-alcaraz-carrion/" rel="alternate" type="text/html" title="Multimodal analysis using TV data: new tools for the study of language and gesture" /><published>2022-03-09T00:00:00+00:00</published><updated>2022-03-09T00:00:00+00:00</updated><id>/seminars/daniel-alcaraz-carrion</id><content type="html" xml:base="/seminars/2022-03-09-daniel-alcaraz-carrion/"><![CDATA[<h3 id="abstract">Abstract</h3>

<p>In this talk, I will describe some of the data and methods offered by the Red Hen Lab. The first section will be devoted to the NewsScape archive, a television repository with over 400,000 hours of TV news recorded from 2004 until the present. This dataset allows researchers to look up specific linguistic expressions and to obtain all the instances in which they were uttered on TV. The NewsScape library gives access to massive amounts of multimodal data useful for big-data approaches to linguistics, political science and computer science, amongst many other disciplines. To illustrate this, I will present some of my research on temporal and numerical cognition, mixing corpus-based linguistic methods and large-scale gesture analysis.</p>

<p>The second section will focus on new tools for the analysis of visual data and multimodal communication. I will present Open Pose, an open-source Python package that automatically detects body key points, shifting gesture recognition from a manual to a machine-assisted annotation. Following that, I will introduce the Red Hen Anonymizer, a software capable of substituting facial features by using computer-generated images while maintaining facial gestures (e.g., lips, eyebrows). I will finish by introducing some of the tools that are currently being developed in Red Hen, such as a visual lexicon for Aztec hieroglyphs and the integration of PRAAT for the analysis of acoustic features.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>

<p>Dr Daniel Alcaraz-Carrión is a postdoctoral researcher at the department of psychology at University of Wisconsin-Madison. He obtained his PhD in Linguistics and English Language at Lancaster University in 2018. His research uses large multimodal databases to examine different aspects of multimodal communication, including language, gesture and other visual representations. He is particularly interested in how people communicate about highly abstract concepts such as time and number, and how language and gesture can vary cross-linguistically. He is a member and collaborator of several international research groups, including the Red Hen Lab, the Daedalus Lab and the Cognitive Development and Communication Lab.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract]]></summary></entry><entry><title type="html">Research for interpreter-centred technology: the case of the AI-powered RSI platform SmarTerp</title><link href="/seminars/2022-2-25-francesca-frittella/" rel="alternate" type="text/html" title="Research for interpreter-centred technology: the case of the AI-powered RSI platform SmarTerp" /><published>2022-02-25T00:00:00+00:00</published><updated>2022-02-25T00:00:00+00:00</updated><id>/seminars/francesca-frittella</id><content type="html" xml:base="/seminars/2022-2-25-francesca-frittella/"><![CDATA[<h3 id="abstract">Abstract</h3>

<p>The lack of consideration of interpreters’ (and translators’) needs in the design of new technological tools has been a major concern of professionals in the T&amp;I industry. This concern has been at the heart of SmarTerp — the remote simultaneous interpreting (RSI) platform powered by artificial intelligence (AI). Thanks to the research efforts of an interdisciplinary team, interpreters’ needs and requirements were incorporated into all stages of SmarTerp’s iterative design and development. This talk presents this cutting-edge technology and sheds light into how research made its interpreter-centred development possible. It will conclude with some reflections on the role of research in the increasing technologisation of the interpreting profession.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>

<p>Francesca Maria Frittella is a conference interpreter (ITA A - ENG B - DEU B - ZHO C), trainer and researcher. She conducted user research and developed training solutions within the SmarTerp project to inform its development into an interpreter-centred solution. Her PhD research at Shanghai International Studies University focuses on the training of conference interpreters on how to effectively integrate AI-powered computer-assisted interpreting (CAI) tools into the SI process. Co-founder of Interpremy, Francesca develops e-courses and teaches research-based workshops for interpreting universities and professional associations.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract]]></summary></entry><entry><title type="html">Automatic Evaluation of Simplified Texts</title><link href="/seminars/2022-2-22-fernando-alva-manchego/" rel="alternate" type="text/html" title="Automatic Evaluation of Simplified Texts" /><published>2022-02-22T00:00:00+00:00</published><updated>2022-02-22T00:00:00+00:00</updated><id>/seminars/fernando-alva-manchego</id><content type="html" xml:base="/seminars/2022-2-22-fernando-alva-manchego/"><![CDATA[<h3 id="abstract">Abstract</h3>

<p>Text Simplification consists of rewriting sentences to make them easier to read and understand, while preserving as much as possible of their original meaning. Human editors simplify by performing several text transformations, such as replacing complex terms by simpler synonyms, reordering words or phrases, removing non-essential information, and splitting long sentences. Current models for Automatic Text Simplification are data-driven: given a large dataset of parallel original-simplified sentences, models are trained to implicitly learn how to perform a variety of editing operations that aim to make a text easier to read and understand. However, how do we know if this implicit learning of multi-operation simplifications results in automatic outputs with such characteristics? and how can we verify that an automatic output is actually “simpler” than its original version? In this talk, I will shed some light in these questions by: (1) introducing ASSET, a new dataset for tuning and testing of simplification models with multi-operation reference simplifications; and (2) presenting the first meta-evaluation of automatic metrics for Automatic Sentence Simplification focused on simplicity, which shows how much the correlation between metrics and human judgements is affected by factors such as the perceived simplicity of the outputs, the system type, and the set of references used for computation.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>

<p>Fernando Alva Manchego is a Lecturer in the School of Computer Science and Informatics at Cardiff University, where he is a member of the Natural Language Processing research group. Before joining Cardiff, he was a Postdoctoral Research Associate at the University of Sheffield. He holds a PhD from the University of Sheffield, and his thesis focused on Automatic Text Simplification. His research interests include Text Simplification, Readability Assessment, and Evaluation of Natural Language Generation.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract]]></summary></entry><entry><title type="html">Computer Vision Meets Portrait Research</title><link href="/seminars/2022-02-16-thomas-mandl/" rel="alternate" type="text/html" title="Computer Vision Meets Portrait Research" /><published>2022-02-16T00:00:00+00:00</published><updated>2022-02-16T00:00:00+00:00</updated><id>/seminars/thomas-mandl</id><content type="html" xml:base="/seminars/2022-02-16-thomas-mandl/"><![CDATA[<h3 id="abstract">Abstract</h3>

<p>Digital Humanities research is focusing on enriching scholarship in Humanities and Cultural studies by employing digital methods for collecting, preserving and analysing artefacts. The paradigm of Distant Reading has proven to be especially productive. Since the Iconic Turn, research with images and visual material has itself established within the Humanities beyond the classic image sciences. For Digital Humanities, the development of appropriate tools and methods for Distant Viewing, which stands for the automatic analysis of large amounts of visual data with AI algorithms is still an emerging research field. In the last years, considerable progress has been made in image processing, especially through approaches of so-called Deep Learning. Thus, the classification of photographs is done based on algorithms, which not only learn the illustration but also, which aspects of the pictures need to be analysed. A prototypical system is a Convolutional Neural Network that combines many simple neurons as processors into complex architectures. This talk will briefly introduce CNNs. A review of approaches of Distant Viewing approaches and systems will be given. Then, the talk will report on experiences from working with image collections in two projects. One is about a collection of 32,000 early modern portraits. The other one deals with collections of pedagogical images mainly from children and youth literature. The goals include print type classification, object detection, similarity of publishers and face recognition on portraits. A discussion will introduce the challenges of processing historical data and working with concepts from the humanities.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>

<p>Thomas Mandl is a Professor of Information Science at the University of Hildesheim. He received his Doctorate in information science at the University of Hildesheim in 2000. He was appointed as an extraordinary professor at the same university in 2010. He is well known for his work in human-machine interaction (usability, method research, international aspects) and user-oriented evaluation in information retrieval. He is also the lead organiser in HASOC shared task – Hate Speech and Offensive Content Identification in English and Indo-Aryan Languages from 2019. His most recent work in applying computer vision to portrait graphics has created a new direction in digital humanities research.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract]]></summary></entry><entry><title type="html">Towards Online Adaptation for Automatic Post-Editing Models</title><link href="/seminars/2022-1-28-marie-escribe/" rel="alternate" type="text/html" title="Towards Online Adaptation for Automatic Post-Editing Models" /><published>2022-01-28T00:00:00+00:00</published><updated>2022-01-28T00:00:00+00:00</updated><id>/seminars/marie-escribe</id><content type="html" xml:base="/seminars/2022-1-28-marie-escribe/"><![CDATA[<h3 id="abstract">Abstract</h3>
<p>Despite the increasingly good quality of automatic translations, machine-translated texts require corrections. Automatic post-editing models have been introduced to perform these corrections without human intervention. However, no system has been able to fully automate the post-editing process. Moreover, while numerous translation tools benefit from translators’ input, human-computer interaction has been underexplored in post-editing.</p>

<p>This talk will discuss automatic post-editing models and suggest that they could be improved in more interactive scenarios, as previously done in machine translation. While some attempts were made to update automatic post-editing models incrementally, this was mostly done using synthetic corpora, which is likely to affect the performance. To address this issue and as part of this project, automatic post-editing models trained in a traditional setting were developed and updated in both batch and online modes without using artificial resources, with a view to analysing the performance of incremental adaptations in different systems, domains and language pairs. While the interaction with the translator was simulated, an interactive functionality allowing for dynamic post-editing was included for demonstration purposes. The results showed that none of the models was able to beat the baseline and that the online models systematically yielded a lower performance. Moreover, this study provided a human evaluation of the outputs obtained in both batch and online models, which constitutes a significant contribution, given that online models tend to be examined using automatic metrics only. This evaluation allowed for identifying recurrent error patterns, such as incorrect deletions, insertions and substitutions, as well as errors related to sentence structure and figurative language.</p>

<p>Such outcomes confirm the difficulties faced in automatic post-editing. Based on the results, several recommendations will be put forward for conducting further research, including experiments with more data and different environmental variables.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>
<p>Marie Escribe holds a BA in Applied Foreign Languages from the University of Haute-Alsace and an MA in Translation from London Metropolitan University. She has worked as a freelance translator specialised in scientific and technical fields for more than two years. Since 2019, she has indeed established strong collaborations with several LSPs and has been entrusted with various responsibilities, going from translation and transcreation to post-editing and project management.
Her experience working with machine translation and CAT tools combined with her strong interest in language technologies led her to another Master’s in Computational Linguistics at the Research Group in Computational Linguistics, University of Wolverhampton, which she completed in 2021.
Her research interests revolve around translation technologies and include in particular post-editing, translation memory systems and translation quality evaluation.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract Despite the increasingly good quality of automatic translations, machine-translated texts require corrections. Automatic post-editing models have been introduced to perform these corrections without human intervention. However, no system has been able to fully automate the post-editing process. Moreover, while numerous translation tools benefit from translators’ input, human-computer interaction has been underexplored in post-editing.]]></summary></entry><entry><title type="html">Let’s Transform Law with Augmented Lawyering: Advances and Challenges in Legal Text Processing</title><link href="/seminars/2022-1-26-ilias-chalkidis/" rel="alternate" type="text/html" title="Let’s Transform Law with Augmented Lawyering: Advances and Challenges in Legal Text Processing" /><published>2022-01-26T00:00:00+00:00</published><updated>2022-01-26T00:00:00+00:00</updated><id>/seminars/ilias-chalkidis</id><content type="html" xml:base="/seminars/2022-1-26-ilias-chalkidis/"><![CDATA[<h3 id="abstract">Abstract</h3>
<p>Law is one of the cornerstones of our civilisation. The legal industry produces constantly large volumes of legal text in various forms, i.e, legislation, court decisions, and legal agreements (contracts). Hence, consuming and understanding legal information can be overwhelming, as the points of interest for users (legal professionals and laypersons) are hidden in piles of pages and documents. Legal Text Processing (a.k.a. Legal NLP or Intelligence) is a growing research area where Natural Language Processing (NLP) techniques are applied in the legal domain. In this talk, I will first point out the main challenges of legal NLP and how the field is advancing. In this regard, I will first argue on the importance of proper benchmarking, and the development of legal-oriented language models. Then I will cover parts of my recent work on large-scale classification under temporal drift, and “baby” steps for cross-lingual legal NLP, decision explainability, robustness, and fairness.</p>

<blockquote>
  <p>What the blockchain will do especially in its NFT form on top of Ethereum is create a world that will eat up all of the contracts. Every contract in the next 15 years will be done on the blockchain.
<em>2021, Gary Vaynerchuk (<a href="https://twitter.com/garyvee">@garyvee</a>)</em></p>
</blockquote>

<h3 id="speakers-bio">Speaker’s bio</h3>
<p>Ilias Chalkidis is a post-doctoral researcher at the Department of Computer Science at the University of Copenhagen (CoAStaL NLP Group). He received his PhD from the Department of Informatics at Athens, University of Economics and Business on Deep Learning for Legal Text Processing. He is well known for his work in Legal Natural Language Processing (LegalNLP), also known as Legal Intelligence. He has published in top-tier conferences such as ACL, NAACL, EMNLP, and EACL. He is the lead developer of LEGAL-BERT which has more than 35,000 downloads from the community, and LEX-GLUE, the benchmark for Legal Language Understanding. Furthermore, he serves in the organizing committee of the Natural Legal Language Processing (NLLP) Workshop.</p>

<p>More information on <a href="https://iliaschalkidis.github.io">https://iliaschalkidis.github.io</a></p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract Law is one of the cornerstones of our civilisation. The legal industry produces constantly large volumes of legal text in various forms, i.e, legislation, court decisions, and legal agreements (contracts). Hence, consuming and understanding legal information can be overwhelming, as the points of interest for users (legal professionals and laypersons) are hidden in piles of pages and documents. Legal Text Processing (a.k.a. Legal NLP or Intelligence) is a growing research area where Natural Language Processing (NLP) techniques are applied in the legal domain. In this talk, I will first point out the main challenges of legal NLP and how the field is advancing. In this regard, I will first argue on the importance of proper benchmarking, and the development of legal-oriented language models. Then I will cover parts of my recent work on large-scale classification under temporal drift, and “baby” steps for cross-lingual legal NLP, decision explainability, robustness, and fairness.]]></summary></entry><entry><title type="html">A Single Model for Many Languages with Adapters</title><link href="/seminars/2022-1-25-ahmet-ustun/" rel="alternate" type="text/html" title="A Single Model for Many Languages with Adapters" /><published>2022-01-25T00:00:00+00:00</published><updated>2022-01-25T00:00:00+00:00</updated><id>/seminars/ahmet-ustun</id><content type="html" xml:base="/seminars/2022-1-25-ahmet-ustun/"><![CDATA[<h3 id="abstract">Abstract</h3>

<p>Recent advances in pre-trained language models have brought the idea of truly multilingual models for many languages, in different tasks. However, cross-language interference and restrained model capacity, i.e. curse of multilinguality, remain as the major obstacle especially for zero or low resource languages. Adapters (Houlsby et al., 2019) that are small bottleneck layers inserted into Transformer models, enable modular and efficient transfer learning. They can also be purposed as a solution to the curse of multilinguality.  In this talk, I will discuss how to use adapters to build a single model for many languages including zero-shot and unsupervised scenarios in dependency parsing and neural machine translation respectively.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>
<p>Ahmet Ustun is a PhD Student in the Center for Language and Cognition (CLCG) at the University of Groningen. He is working as a member of the Computational Linguistics research group under the supervision of Arianna Bisazza, Gosse Bouma and Gertjan van Noord. His research focuses on multilingual natural language processing with a special interest in cross-lingual transfer learning. In this context, he worked on cross-lingual word embeddings, multilingual dependency parsing and multilingual unsupervised NMT. His research aim is to find efficient multilingual adaptation methods for low-resource languages without suffering the curse of multilinguality.</p>

<p>Website: <a href="https://ahmetustun.github.io">https://ahmetustun.github.io</a></p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract]]></summary></entry><entry><title type="html">Text-to-sign translation: making information accessible</title><link href="/seminars/2021-12-12-lyke-esselink/" rel="alternate" type="text/html" title="Text-to-sign translation: making information accessible" /><published>2021-12-12T00:00:00+00:00</published><updated>2021-12-12T00:00:00+00:00</updated><id>/seminars/lyke-esselink</id><content type="html" xml:base="/seminars/2021-12-12-lyke-esselink/"><![CDATA[<h3 id="abstract">Abstract</h3>
<p>Communication between healthcare professionals and deaf patients is challenging, and the current COVID-19 pandemic makes this issue even more acute. Sign language interpreters can often not enter hospitals and face masks make lipreading impossible. To address this urgent problem, SignLab Amsterdam developed a system which allows healthcare professionals to translate sentences that are frequently used in the diagnosis and treatment of COVID-19 into Sign Language of the Netherlands (NGT). Translations are displayed by means of videos and avatar animations. The architecture of the system is such that it could be extended to other applications and other sign languages in a relatively straightforward way.</p>

<p>In the first part of this talk, I will present an overview of the system created by SignLab Amsterdam. I will provide a background on the problem at hand, explain the basics of sign languages and sign synthesis, and outline our system and the process behind its implementation. The second part of the talk will focus on an extensive evaluation study that we did, of which the results are not yet published. I will cover the methodology of this study, some important lessons that we learned from the process, and unveil some of the results.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>
<p>Lyke Esselink is a Master’s student in Artificial Intelligence at the Radboud University in Nijmegen, and completed her bachelor’s degree in AI at the University of Amsterdam. Since the start of 2020, she combined her education with her interest in sign language through research at SignLab Amsterdam, where she has investigated the translation of text to Sign Language of the Netherlands. Research interest areas include Machine Translation, Natural Language Processing and accessibility technologies.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract Communication between healthcare professionals and deaf patients is challenging, and the current COVID-19 pandemic makes this issue even more acute. Sign language interpreters can often not enter hospitals and face masks make lipreading impossible. To address this urgent problem, SignLab Amsterdam developed a system which allows healthcare professionals to translate sentences that are frequently used in the diagnosis and treatment of COVID-19 into Sign Language of the Netherlands (NGT). Translations are displayed by means of videos and avatar animations. The architecture of the system is such that it could be extended to other applications and other sign languages in a relatively straightforward way.]]></summary></entry><entry><title type="html">Modern Enterprise Translation Management: Problems, Compliance and Resources</title><link href="/seminars/2021-12-3-todor-lazarov/" rel="alternate" type="text/html" title="Modern Enterprise Translation Management: Problems, Compliance and Resources" /><published>2021-12-03T00:00:00+00:00</published><updated>2021-12-03T00:00:00+00:00</updated><id>/seminars/todor-lazarov</id><content type="html" xml:base="/seminars/2021-12-3-todor-lazarov/"><![CDATA[<h3 id="abstract">Abstract</h3>
<p>Modern-day LSP companies have extensive translation experience and deep industry know-how. They work with vendors who already use “some” language technology – e.g. certain CAT tools, certain file formats, etc. Companies often own, but unfortunately rarely have full control of their linguistic assets and resources. LSPs benefit from TM usage and leverage, but usually they find it difficult to manage their production process and to effectively manage their linguistic resources.</p>

<p>Most probably these statements describe the most common situation for most LSPs! In this presentation the author will outline the most common problems for modern day LSP companies regarding the effective management of internal and external linguistic resources. We will elaborate on compliance problems (such as compliance with the industry specialized ISO 17100) and we will try to construct and describe a system for effective management of linguistic resources and ROI.</p>

<p>The current trend is to collect linguistic resources with as much as possible meta-information, but rarely this meta-information is useful for practical business purposes – we will try to elaborate on how converting this “artefacts” into useful “instruments” can benefit the production process and in addition – how the mainstream LSP production process can be used to create resources for different NLP tasks.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>
<p>Dr. Todor Lazarov holds a PhD degree in Computational linguistics and has a diverse background in Linguistics. He has also specialized Artificial Intelligence in the University of Amsterdam. Todor teaches courses in the programmes of the Centre for Computational and Applied Linguistics in New Bulgarian University and he is also working as Research and Development Manager at Sofita Translation Agency. He has a diverse experience with CAT tools and has also established successful collaboration with different commercial MT providers. His research interests include machine translation, modern translation technologies, machine translation evaluation and CAT tools. Todor is also providing subject matter expertise and consultation to different LSP`s in Bulgaria.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract Modern-day LSP companies have extensive translation experience and deep industry know-how. They work with vendors who already use “some” language technology – e.g. certain CAT tools, certain file formats, etc. Companies often own, but unfortunately rarely have full control of their linguistic assets and resources. LSPs benefit from TM usage and leverage, but usually they find it difficult to manage their production process and to effectively manage their linguistic resources.]]></summary></entry><entry><title type="html">Integration of TM and MT</title><link href="/seminars/2021-11-26-rocio-caro/" rel="alternate" type="text/html" title="Integration of TM and MT" /><published>2021-11-26T00:00:00+00:00</published><updated>2021-11-26T00:00:00+00:00</updated><id>/seminars/rocio-caro</id><content type="html" xml:base="/seminars/2021-11-26-rocio-caro/"><![CDATA[<h3 id="abstract">Abstract</h3>
<p>Translation Memories (TM) and Machine Translation (MT) have been used by translators for a long time, but research has mainly studied them separately until very recently. Nowadays, however, not only academic research is focused on the integration of TM and MT, but many CAT tools include the possibility of working with an MT engine as well. Some companies claim that the integration of the two technologies is beneficial for translators as it may increase their productivity, but there are not comprehensive studies on the topic and very little is known about the efforts, productivity and opinion of translators on using translation tools that integrate TM and MT, and the quality of the final texts.</p>

<p>In the first part of the talk, I will present the different ways TM and MT can be integrated, which are divided into two main categories: internal or external integration. In the second part, I will present the project we are currently carrying out to study the post-editing efforts (technical, temporal, and cognitive) of translators working in an external integrated environment (i.e., both TM and MT segments are presented to the translator), the preliminary findings, what we found about the opinion of translators, and the next steps of the project.</p>

<h3 id="speakers-bio">Speaker’s bio</h3>
<p>Rocío Caro is currently doing her PhD in Translation Technology at the Research Group of Computational Linguistics, University of Wolverhampton. She has an MA in Translation for the Publishing World and a BA in Translation and Interpreting from the University of Malaga, Spain.</p>]]></content><author><name>RGCL</name></author><summary type="html"><![CDATA[Abstract Translation Memories (TM) and Machine Translation (MT) have been used by translators for a long time, but research has mainly studied them separately until very recently. Nowadays, however, not only academic research is focused on the integration of TM and MT, but many CAT tools include the possibility of working with an MT engine as well. Some companies claim that the integration of the two technologies is beneficial for translators as it may increase their productivity, but there are not comprehensive studies on the topic and very little is known about the efforts, productivity and opinion of translators on using translation tools that integrate TM and MT, and the quality of the final texts.]]></summary></entry></feed>